{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 100\n",
    "output_size = 1\n",
    "lr = 1e-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN():\n",
    "    #model parameters\n",
    "    Wxh = torch.randn(hidden_size, output_size)*0.01         #Input to hidden\n",
    "    Whh = torch.randn(hidden_size, hidden_size)*0.01        #Hidden to itself\n",
    "    Why = torch.randn(output_size, hidden_size)*0.01         #Hidden to output\n",
    "    Bh =  torch.zeros(hidden_size, 1)                       #Hidden Bias\n",
    "    By =  torch.zeros(output_size, 1)                         #Output Bias\n",
    "    \n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.xs = {}                                       #will store encoded input\n",
    "        self.hs = {}                                       #Store hidden state output\n",
    "        self.ys = {}                                       #Store output\n",
    "        self.ps = {}                                       #Probabilities of next character\n",
    "        self.dWxh = torch.zeros_like(Wxh)\n",
    "        self.dWhh = torch.zeros_like(Whh)\n",
    "        self.dWhy = torch.zeros_like(Why)\n",
    "        self.dBh  = torch.zeros_like(Bh)\n",
    "        self.dBy  = torch.zeros_like(By)\n",
    "        \n",
    "    def forward(self, inputs, h_initial):             #h_initial is Hx1 array of initial hidden state\n",
    "\n",
    "        hs[-1] = torch.copy(h_initial)\n",
    "        for i in range(len(inputs)):\n",
    "            xs[i] = torch.zeros(output_size,1)\n",
    "            xs[i][inputs[i]] = 1\n",
    "            #hidden_state = input*Wxh + last_value_of_hidden_layer*Whh + Bias\n",
    "            hs[i] = torch.tanh(torch.dot(Wxh, xs[i]) + torch.dot(Whh, hs[i-1]) + Bh)        #Hidden State\n",
    "            ys[i] = torch.dot(Why, hs[i]) + By\n",
    "            ps[i] = torch.exp(ys[i])/torch.sum(torch.exp(ys[i]))    #Noramlized Probability\n",
    "            \n",
    "            return ps\n",
    "            \n",
    "            \n",
    "    def backward(self, inputs):\n",
    "        dhnext = np.zeros_like(hs[0])\n",
    "        for i in reversed(range(len(inputs))):\n",
    "            dy = torch.copy(ps[i])         #Our first gradient\n",
    "            dy[targets[t]] -= 1             #back prop in y\n",
    "            dWhy = +=\n",
    "            \n",
    "                \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2679)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.dot(torch.rand(1),torch.randn(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hprev' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-ae0b25a713ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhprev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'hprev' is not defined"
     ]
    }
   ],
   "source": [
    "np.copy(hprev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = range(0,2)\n",
    "x[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.9637, 0.9079, 0.1505, 0.0396, 0.5349, 0.8915],\n",
       "         [0.9686, 0.0176, 0.4907, 0.1902, 0.3456, 0.7142],\n",
       "         [0.0994, 0.6461, 0.3625, 0.5144, 0.1014, 0.1121]],\n",
       "\n",
       "        [[0.9973, 0.1343, 0.4454, 0.4769, 0.5726, 0.7223],\n",
       "         [0.5168, 0.1661, 0.7746, 0.9220, 0.6032, 0.0254],\n",
       "         [0.0704, 0.3400, 0.2635, 0.8172, 0.2101, 0.2981]]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.rand(2, 3,6)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.transpose(y,0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2, 6])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
